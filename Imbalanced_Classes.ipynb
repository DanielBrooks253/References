{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "from sklearn.experimental import enable_iterative_imputer\r\n",
    "from sklearn.utils import resample\r\n",
    "from sklearn import ensemble, impute, model_selection, preprocessing, tree, linear_model, feature_selection\r\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweak_titanic(df):\r\n",
    "    return df.drop(['name', 'ticket', 'home.dest', 'boat', 'body', 'cabin'], axis=1) \\\r\n",
    "             .pipe(pd.get_dummies, drop_first=True)\r\n",
    "\r\n",
    "def get_train_test_X_y(df, y_col, test_size=0.3, std_cols=None):\r\n",
    "    y = df[y_col]\r\n",
    "    x = df.drop(y_col, axis=1)\r\n",
    "\r\n",
    "    num_cols = [\r\n",
    "        \"pclass\",\r\n",
    "        \"age\",\r\n",
    "        \"sibsp\",\r\n",
    "        \"parch\",\r\n",
    "        \"fare\"]\r\n",
    "\r\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=test_size, random_state=42)\r\n",
    "    fi = impute.IterativeImputer()\r\n",
    "\r\n",
    "    X_train.loc[:, num_cols]=fi.fit_transform(X_train[num_cols])\r\n",
    "    X_test.loc[:, num_cols] = fi.transform(X_test[num_cols])\r\n",
    "\r\n",
    "    if std_cols:\r\n",
    "        std = preprocessing.StandardScaler()\r\n",
    "        X_train.loc[:, std_cols] = std.fit_transform(X_train[std_cols])\r\n",
    "        X_test.loc[:, std_cols] = std.transform(X_test[std_cols])\r\n",
    "\r\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel.brooks\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexing.py:1737: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\daniel.brooks\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexing.py:1737: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\daniel.brooks\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexing.py:1737: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\daniel.brooks\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexing.py:1737: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('titanic3.csv')\r\n",
    "ti_df = tweak_titanic(df)\r\n",
    "std_cols = \"pclass,age,sibsp,fare\".split(\",\")\r\n",
    "X_train, X_test, y_train, y_test = get_train_test_X_y(\r\n",
    "    ti_df, \"survived\", std_cols=std_cols\r\n",
    ")\r\n",
    "\r\n",
    "X = pd.concat([X_train, X_test])\r\n",
    "y = pd.concat([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    809\n",
       "1    500\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    809\n",
       "1    809\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upsample\r\n",
    "mask = df['survived']==1\r\n",
    "surv_df = df[mask]\r\n",
    "death_df = df[~mask]\r\n",
    "\r\n",
    "df_upsample = resample(\r\n",
    "    surv_df,\r\n",
    "    replace=True,\r\n",
    "    n_samples=len(death_df),\r\n",
    "    random_state=42)\r\n",
    "\r\n",
    "df2 = pd.concat([death_df, df_upsample])\r\n",
    "df2['survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    809\n",
       "1    809\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=42)\r\n",
    "X_ros, y_ros = ros.fit_resample(X, y)\r\n",
    "pd.Series(y_ros).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    809\n",
       "1    809\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42)\r\n",
    "X_sm, y_sm = sm.fit_resample(X, y)\r\n",
    "pd.Series(y_sm).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    809\n",
       "1    777\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This method is similar to SMOTE but it generates different number of samples depending on an estimate of the local distribution of the class to be oversampled.\r\n",
    "\r\n",
    "ady = ADASYN(random_state=42)\r\n",
    "X_ady, y_ady = ady.fit_resample(X, y)\r\n",
    "pd.Series(y_ady).value_counts()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}